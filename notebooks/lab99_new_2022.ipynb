{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/full-stack-deep-learning/fsdl-text-recognizer-2022/blob/main/notebooks/lab99_new_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpjrrEFVMgEG"
      },
      "source": [
        "This notebook walks you through environment setup, model training, and deployment for FSDL in its new 2022 iteration.\n",
        "\n",
        "Right now, it's only expected to work on Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqPe8HfMThuH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uklU2RGrhtyq"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "in_colab = \"google.colab\" in sys.modules\n",
        "repo = \"fsdl-text-recognizer-2022\"\n",
        "\n",
        "assert in_colab\n",
        "\n",
        "!git clone https://github.com/full-stack-deep-learning/{repo}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTeioV18GXiC"
      },
      "source": [
        "Now we `cd` into the cloned repo and take a look around."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDR54ZV1j5_P"
      },
      "outputs": [],
      "source": [
        "%cd /content/{repo}/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zJ1uDn1Gc4b"
      },
      "source": [
        "We need to install the `requirements` for both `prod`uction and `dev`evelopment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe_D_UW8GiUS"
      },
      "source": [
        "Timing our installs so we can keep an eye on the latency from opening a Colab to doing useful work.\n",
        "\n",
        "It should never be more than three minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICSOw7MwEizK"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "!pip install -r requirements/prod.in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1L0f7pyGprc"
      },
      "source": [
        "We also install the requirements from `dev`, using a cute `sed`/`xargs` CLI combo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjX-dnEMeBWF"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "!sed 1d requirements/dev.in | grep -v \"#\" | xargs pip install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPEKQAmierzV"
      },
      "source": [
        "## Finalizing Setup and Checking Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVcZ-50GXupi"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl  # do we have our dev dependencies?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51mzAe9MG_w8"
      },
      "source": [
        "We update the `PYTHONPATH` so that the library is on the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFfejRtEZLOl"
      },
      "outputs": [],
      "source": [
        "pythonpath = !echo $PYTHONPATH\n",
        "if \".\" not in pythonpath[-1]:\n",
        "  pythonpath = [\".\"] + pythonpath\n",
        "  %env PYTHONPATH={\":\".join(pythonpath)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5ygaaRoG7b2"
      },
      "source": [
        "We turn on autoreload to allow \"hot\" code editing in the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNgLee6dZRW5"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKqWX9zgHGtt"
      },
      "source": [
        "Then we check to make sure it's all importable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zztToruiZHD-"
      },
      "outputs": [],
      "source": [
        "import text_recognizer\n",
        "import training  # ✨ NEW 2022: training is now a module of its own"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MAJdQC_ZY3i"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.paragraph_text_recognizer import ParagraphTextRecognizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvwoCr4bte_d"
      },
      "outputs": [],
      "source": [
        "import text_recognizer.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoJJRFpJH_Oq"
      },
      "source": [
        "## Training\n",
        "\n",
        "Training is still primarily done through the `run_experiment.py` script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON4KbRAjMHaz"
      },
      "source": [
        "#### Unfurl this section to see the `--help` output.\n",
        "\n",
        "For help with data/model-specific arguments, provide a `--data_class` and `--model_class` in addition to `--help`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiiQQzA2IJqw"
      },
      "outputs": [],
      "source": [
        "%run training/run_experiment.py --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn_ZrXb_LT9r"
      },
      "source": [
        "### MNIST Hello World!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDt-bTlLMXFr"
      },
      "source": [
        "We start off with something really simple: one epoch of digit recognition with local logging and no acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFot8A0H1Dvp"
      },
      "outputs": [],
      "source": [
        "%run training/run_experiment.py --gpus=0 --max_epochs 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF74F8saLarf"
      },
      "source": [
        "### Profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALE6MjHGHdXW"
      },
      "source": [
        "We now have the PyTorch profiler available (outside of distributed training, where profiling is still hard).\n",
        "\n",
        "Just pass the `--profile` flag in to `training/run_experiment.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CidyYo1ZHzoZ"
      },
      "source": [
        "The cell below profiles the `ResnetTransformer` on the real dataset.\n",
        "\n",
        "You can see an example profile (in Tensorboard on W&B) [here](https://wandb.ai/cfrye59/test-colab-profile/runs/26au3nsn/tensorboard?workspace=user-cfrye59).\n",
        "\n",
        "Read about how to read the traces in these profiles [here](http://wandb.me/trace-report).\n",
        "\n",
        "You'll also find very basic profiling information printed to the `stdout`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sniC8TP1Kg9H"
      },
      "source": [
        "> Note that you'll need to provide a W&B auth key for this cell to finish running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKVvy2C4LcG4"
      },
      "outputs": [],
      "source": [
        "!WANDB_PROJECT=test-colab-profile python training/run_experiment.py --wandb --gpus=-1 \\\n",
        "  --data_class=IAMOriginalAndSyntheticParagraphs --model_class=ResnetTransformer --loss=transformer \\\n",
        "  --batch_size=64 --lr=0.0001 \\\n",
        "  --max_epochs=1 --precision 16 --profile --max_steps=16 --limit_test_batches=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQAS_wyzJ0lZ"
      },
      "source": [
        "### ✨ NEW 2022: Richer Prediction Logging\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUx_cBVuJ_dc"
      },
      "source": [
        "The prediction logging has been migrated to W&B Tables,\n",
        "which means we now have richer interfaces for interaction\n",
        "with what we've put up.\n",
        "\n",
        "Check some out [here](https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/artifacts/run_table/run-1vrnrd8p-trainpredictions/v194/files/train/predictions.table.json) (or run the cell below to view them inside the notebook).\n",
        "\n",
        "View\n",
        "[this report](https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/reports/Strings-are-truncated-appropriately-with-new-decode-method---VmlldzoxOTkxMTQ2)\n",
        "for an example of them in use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xJ6AR0bGwDn"
      },
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "logged_preds_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/artifacts/run_table/run-1vrnrd8p-trainpredictions/v194/files/train/predictions.table.json\"\n",
        "\n",
        "IFrame(logged_preds_url, width=1024, height=768)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvzCYLrFLWVB"
      },
      "source": [
        "### Overfitting Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0JdDax5Igyq"
      },
      "source": [
        "We now have a special script for testing whether the model can fit a small dataset -- wrapping `--overfit_batches` in PyTorch Lightning.\n",
        "\n",
        "Specifically, we check whether it reaches a criterion loss value within a certain number of passes over that small dataset.\n",
        "\n",
        "With default arguments, it should complete\n",
        "in under 10 minutes on a commodity GPU (e.g. on Colab) --\n",
        "it runs \"just\" 100 epochs.\n",
        "\n",
        "Fully using the \"overfitting trick\" requires getting the loss down to levels close to what you are targeting in training.\n",
        "That takes 5-10x longer.\n",
        "\n",
        "You can see some of the work done using the overfitting trick in W&B Reports [here](https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/reports/Overfit-Check-After-Refactor--VmlldzoyMDY5MjI1) and [here](https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/reports/Overfitting-Studies-2022-05--VmlldzoyMDU2OTQ0).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a8-N8IkozPm"
      },
      "outputs": [],
      "source": [
        "!WANDB_PROJECT=fsdl-test-overfitting ./training/tests/overfit.sh 10 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPSP1hKJB2-l"
      },
      "source": [
        "### \"Serious\" Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SqpZi8rJLl4"
      },
      "source": [
        "Now that we've\n",
        "1. done our \"hello world\" on MNIST,\n",
        "2. profiled our code to look for compute performance issues, and\n",
        "3. debugged our code for optimization performance issues by overfitting,\n",
        "\n",
        "we're ready for some \"serious\" training\n",
        "(but not actually, because it'd take like 24 hours or more on Colab)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DztVq4WLxWQ2"
      },
      "outputs": [],
      "source": [
        "train_for_real = False  # flip this switch to run training; but note that it takes a long time\n",
        "\n",
        "if train_for_real:\n",
        "  %run training/run_experiment.py --gpus=-1 --data_class=IAMOriginalAndSyntheticParagraphs --model_class=ResnetTransformer \\\n",
        "  --loss=transformer --batch_size=64 --accumulate_grad_batches 4 --log_every_n_steps=500 --lr=0.0004 \\\n",
        "  --precision 16 --max_epochs=1500 --check_val_every_n_epoch=3 --wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXhFI2j4EMec"
      },
      "source": [
        "## Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjk_mEVxOpso"
      },
      "source": [
        "Once a model is trained, the next step is to put it in production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNMJpRZUJPN3"
      },
      "source": [
        "### Discrete Model Staging using W&B and TorchScript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmYwdw7FO8Pk"
      },
      "source": [
        "We've got a new \"two-step\" approach, so that development and production can be cleanly separated (e.g. no Lightning in prod).\n",
        "\n",
        "Specifically, we create a version-controlled artifact for\n",
        "the TorchScript-compiled model.\n",
        "This format of the model is very portable -- it can even be run without Python!\n",
        "\n",
        "We use W&B to store the versions of both the model checkpoint and the Torchscript model.\n",
        "\n",
        "From scratch, we'd pull a model checkpoint (as output by Lightning) down from W&B, jit script it with Torch, and then upload\n",
        "the TorschSrupt model.\n",
        "\n",
        "This workflow is encapsulated in the `training/stage_model.py` script.\n",
        "\n",
        "But since this process has already been done\n",
        "for a workable text recognizer,\n",
        "here we will just `--fetch` the TorchScript model\n",
        "to put it on the local disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP1jn50szrhS"
      },
      "outputs": [],
      "source": [
        "%run training/stage_model.py --fetch \\\n",
        "  --entity \"cfrye59\" --from_project \"fsdl-text-recognizer-2021-training\"\n",
        "# see --help docs for more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIym4tsHHbYD"
      },
      "source": [
        "### Gradio Frontend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTzLQEcdI60h"
      },
      "source": [
        "Our model now has a frontend based on Gradio.\n",
        "That frontend includes user feedback."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBbFpysuJNqb"
      },
      "source": [
        "Using `gradio` on Colab after requires a restart for now, due to conflict over Jinja versions --\n",
        "this is an issue we want to resolve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYiVZ5ECJ4WD"
      },
      "source": [
        "The code below runs the model we just fetched locally\n",
        "inside the same Python process as the Gradio frontend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_PF1MT0HnEO"
      },
      "outputs": [],
      "source": [
        "from app_gradio.app import PredictorBackend, make_frontend\n",
        "\n",
        "predict = PredictorBackend(url=None).run  # run model \"backend\" in the same process\n",
        "frontend = make_frontend(predict)\n",
        "\n",
        "frontend.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB2xQ9n_HR3D"
      },
      "source": [
        "### Public AWS Lambda URL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3kbnK_MKBEO"
      },
      "source": [
        "The above architecture is not great,\n",
        "because it couples frontend and backend directly.\n",
        "\n",
        "So we instead use the serverless api from 2021,\n",
        "with an enhancement: AWS Lambdas now come with a URL that serves\n",
        "as an HTTP endpoint,\n",
        "instead of only being accessible via AWS's internal system of URIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6a4NuaGHuEV"
      },
      "source": [
        "Setting one up requires AWS CLI/UI interaction,\n",
        "so we'll instead just quickly ping an existing Lambda as a proof-of-principle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O62cRdIf5eXw"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from IPython.display import Image\n",
        "import requests\n",
        "\n",
        "lambda_url = \"https://3akxma777p53w57mmdika3sflu0fvazm.lambda-url.us-west-1.on.aws/\"\n",
        "image_url = \"https://fsdl-public-assets.s3-us-west-2.amazonaws.com/paragraphs/a01-077.png\"\n",
        "\n",
        "headers = {\"Content-type\": \"application/json\"}\n",
        "payload = json.dumps({\"image_url\": image_url})\n",
        "\n",
        "if \"pred\" not in locals():\n",
        "  response = requests.post(lambda_url, data=payload, headers=headers)\n",
        "  pred = response.json()[\"pred\"]\n",
        "\n",
        "print(pred)\n",
        "\n",
        "Image(url=image_url, width=512)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ON4KbRAjMHaz"
      ],
      "include_colab_link": true,
      "name": "lab99_new_2022.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
